"""LangGraph workflow for Telegram message processing."""

from typing import Dict, Any, TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from .qwen_langchain import QwenChatModel
from .telegram_mcp import TelegramMCPClient


class ProcessingState(TypedDict):
    """State for the message processing workflow."""
    source_channels: List[str]  # List of channel names/IDs to fetch from
    time_period_minutes: int    # How many minutes back to fetch
    target_channel: str         # Channel to send results to
    raw_messages: List[Dict]    # Raw messages from Telegram
    processed_messages: List[Dict]  # Messages after AI analysis
    error: str
    mcp_session: Any           # Store MCP session for reuse
    custom_filter_rules: List[str]  # Custom filtering rules


async def fetch_messages_from_channels_node(state: ProcessingState) -> Dict[str, Any]:
    """Fetch messages from specified Telegram channels for given time period."""
    print("[DEBUG] Starting fetch_messages_from_channels_node")
    
    try:
        from .telegram_mcp_client import TelegramMCPClient
        telegram_client = TelegramMCPClient()
        
        all_messages = []
        source_channels = state.get("source_channels", ["BitKogan / Development"])
        time_period = state.get("time_period_minutes", 10)
        
        for channel in source_channels:
            print(f"[DEBUG] Fetching from channel: {channel}")
            messages = await telegram_client.get_recent_messages(
                chat_name=channel,
                minutes_back=time_period
            )
            all_messages.extend(messages)
        
        print(f"[DEBUG] Total messages fetched: {len(all_messages)}")
        
        return {
            "raw_messages": all_messages,
            "error": "",
            "mcp_session": telegram_client
        }
        
    except Exception as e:
        print(f"[DEBUG] Error fetching messages: {e}")
        return {
            "raw_messages": [],
            "error": f"Failed to fetch messages: {str(e)}",
            "mcp_session": None
        }


async def analyze_messages_node(state: ProcessingState) -> Dict[str, Any]:
    """Analyze each message individually: rephrase or filter out."""
    print("[DEBUG] Starting analyze_messages_node")
    
    raw_messages = state.get("raw_messages", [])
    if not raw_messages:
        return {"processed_messages": []}
    
    print(f"[DEBUG] First message structure: {raw_messages[0] if raw_messages else 'No messages'}")
    
    try:
        # Get current user info for mention detection
        mcp_session = state.get("mcp_session")
        user_mentions = []
        if mcp_session:
            try:
                user_info = await mcp_session.get_current_user()
                if user_info.get('username'):
                    user_mentions.append(f"@{user_info['username']}")
                if user_info.get('first_name'):
                    user_mentions.append(user_info['first_name'])
                if user_info.get('name'):
                    user_mentions.append(user_info['name'])
                user_mentions = [m for m in user_mentions if m and m != '@']
                print(f"[DEBUG] User mentions to check: {user_mentions}")
            except Exception as e:
                print(f"[DEBUG] Could not get user info: {e}")
        
        llm = QwenChatModel()
        processed_messages = []
        
        mentions_text = ", ".join(user_mentions) if user_mentions else "–Ω–µ —É–∫–∞–∑–∞–Ω—ã"
        
        # Build custom filter rules text
        custom_rules_text = ""
        custom_filter_rules = state.get("custom_filter_rules", [])
        if custom_filter_rules:
            custom_rules_text = "\n\n–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê –§–ò–õ–¨–¢–†–ê–¶–ò–ò:\n" + "\n".join(f"- {rule}" for rule in custom_filter_rules)
        
        system_prompt = f"""–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ IT-—á–∞—Ç–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω–∏ –æ–¥–Ω–æ –∏–∑ –¥–µ–π—Å—Ç–≤–∏–π:

1. –ü–ï–†–ï–§–†–ê–ó–ò–†–û–í–ê–¢–¨ - –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–≤–∫–ª—é—á–∞—è —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –≤–∞–∂–Ω—ã–µ —Ç–µ–º—ã, –ø–ª–∞–Ω—ã, —Ä–µ—à–µ–Ω–∏—è)
2. –û–¢–§–ò–õ–¨–¢–†–û–í–ê–¢–¨ - —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —è–≤–Ω–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ–µ (—Å–ø–∞–º, –æ–¥–∏–Ω–æ—á–Ω—ã–µ —ç–º–æ–¥–∑–∏, "–æ–∫", "–¥–∞", "+1")

–í–ê–ñ–ù–û: 
- –†–µ–∞–∫—Ü–∏–∏ –Ω–∞ –≤–∞–∂–Ω—ã–µ —Ç–µ–º—ã, –æ–±–µ—â–∞–Ω–∏—è –∏–∑—É—á–∏—Ç—å —á—Ç–æ-—Ç–æ, –ø–ª–∞–Ω—ã –≤—Å—Ç—Ä–µ—á - —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –ù–ï —Ñ–∏–ª—å—Ç—Ä—É–π –∏—Ö
- "–ø—Ä–æ–¥" = "–ø—Ä–æ–¥–∞–∫—à–Ω" (production), –Ω–µ "–ø—Ä–æ–¥–∞–∂–∞"
- –°–æ—Ö—Ä–∞–Ω—è–π IT-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é: —Ä–µ–ª–∏–∑, —Ö–æ—Ç—Ñ–∏–∫—Å, –±—ç–∫–µ–Ω–¥, —ç–Ω–¥–ø–æ–∏–Ω—Ç, –∞–ø–ø—Ä—É–≤ –∏ —Ç.–¥.
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –¥–æ–ø—É—Å—Ç–∏–º —Ç–æ–ª—å–∫–æ –¥–ª—è —É—Å—Ç–æ—è–≤—à–∏—Ö—Å—è IT-—Ç–µ—Ä–º–∏–Ω–æ–≤ (API, backend, frontend, deploy –∏ —Ç.–¥.)
- –°–æ—Ö—Ä–∞–Ω—è–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞
- –ü—Ä–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞: "–≤–ø–µ—á–∞—Ç–ª—è—é—â–∏–π" –≤–º–µ—Å—Ç–æ "impressive", "–æ—Ç–∑—ã–≤" –≤–º–µ—Å—Ç–æ "feedback"
- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–æ—Ö—Ä–∞–Ω—è–π –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (@username) –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏ [ ] –≤ —Ç–µ–∫—Å—Ç–µ - –æ–Ω–∏ –º–µ—à–∞—é—Ç Markdown —Å—Å—ã–ª–∫–∞–º{custom_rules_text}

–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –û–ø—Ä–µ–¥–µ–ª–∏, —É–ø–æ–º—è–Ω—É—Ç –ª–∏ –¢–û–ß–ù–û —Ç–µ–∫—É—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏.
–¢–µ–∫—É—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å —É–ø–æ–º—è–Ω—É—Ç –∫–∞–∫: {mentions_text}
–í–ù–ò–ú–ê–ù–ò–ï: –°—Ç–∞–≤—å mentioned=true –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –¢–û–ß–ù–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –æ–¥–Ω–∏–º –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤—ã—à–µ.

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{"action": "rephrase", "text": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", "mentioned": true/false}}
–∏–ª–∏
{{"action": "filter", "reason": "–ø—Ä–∏—á–∏–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏", "mentioned": false}}

–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª –∏ IT-–∫–æ–Ω—Ç–µ–∫—Å—Ç."""
        
        for msg in raw_messages:
            try:
                message_text = msg.get('text', '')
                context = msg.get('context', '')
                
                # Prepare full context for analysis
                full_context = f"–°–æ–æ–±—â–µ–Ω–∏–µ: {message_text}"
                if context:
                    full_context += f"\n–ö–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç): {context}"
                
                chat_messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=full_context)
                ]
                
                result = await llm._agenerate(chat_messages)
                response = result.generations[0].message.content
                
                import json
                analysis = json.loads(response)
                
                print(f"[DEBUG] Message from {msg.get('author')}: {msg.get('text')[:50]}...")
                print(f"[DEBUG] AI decision: {analysis}")
                
                if analysis.get("action") == "rephrase":
                    processed_msg = msg.copy()
                    processed_msg["text"] = analysis["text"]
                    processed_msg["mentioned"] = analysis.get("mentioned", False)
                    processed_messages.append(processed_msg)
                else:
                    print(f"[DEBUG] Filtered out: {analysis.get('reason', 'No reason')}")
                    
            except Exception as e:
                print(f"[DEBUG] Error analyzing message: {e}")
                # Keep original message if analysis fails
                processed_messages.append(msg)
        
        print(f"[DEBUG] Processed {len(processed_messages)} out of {len(raw_messages)} messages")
        
        return {"processed_messages": processed_messages}
        
    except Exception as e:
        print(f"[DEBUG] Error in analyze_messages_node: {e}")
        return {"processed_messages": raw_messages}  # Fallback to original messages


async def send_results_node(state: ProcessingState) -> Dict[str, Any]:
    """Send processed messages to target Telegram channel."""
    print("[DEBUG] Starting send_results_node")
    
    processed_messages = state.get("processed_messages", [])
    target_channel = state.get("target_channel", "infotest")
    mcp_session = state.get("mcp_session")
    
    if not processed_messages:
        print("[DEBUG] No processed messages to send")
        return {"error": "No messages to send"}
    
    if not mcp_session:
        print("[DEBUG] No MCP session available")
        return {"error": "No MCP session available"}
    
    try:
        # Calculate time period info
        from datetime import datetime, timezone, timedelta
        now_msk = datetime.now(timezone(timedelta(hours=3)))
        
        # Always show period as "from X to Y" format
        if state.get("time_period_minutes"):
            # Custom period
            start_time = now_msk - timedelta(minutes=state["time_period_minutes"])
            period_text = f"—Å {start_time.strftime('%H:%M')} –¥–æ {now_msk.strftime('%H:%M')} MSK"
        else:
            # Default: from 8 AM MSK today
            today_8am = now_msk.replace(hour=8, minute=0, second=0, microsecond=0)
            if now_msk < today_8am:
                # If it's before 8 AM, use yesterday 8 AM
                today_8am -= timedelta(days=1)
            period_text = f"—Å {today_8am.strftime('%H:%M')} –¥–æ {now_msk.strftime('%H:%M')} MSK"
        
        # Get source channel name
        source_channels = state.get("source_channels", ["BitKogan / Development"])
        channel_text = ", ".join(source_channels)
        
        # Format messages for sending
        formatted_text = f"–°–≤–æ–¥–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel_text} {period_text}\n\n"
        
        chat_id = 2083014011  # BitKogan / Development group ID for links
        
        message_parts = []
        current_part = formatted_text
        
        for i, msg in enumerate(processed_messages, 1):
            author = msg.get("author", "Unknown")
            text = msg.get("text", "")
            date_str = msg.get("date", "")
            msg_id = msg.get("id", "")
            is_mentioned = msg.get("mentioned", False)  # Use AI-determined mention flag
            
            mention_prefix = "üîî " if is_mentioned else ""
            
            print(f"[DEBUG] Message {msg_id}: mentioned={is_mentioned} (AI-determined)")
            
            # Convert UTC to MSK and format
            if date_str:
                from datetime import datetime, timezone, timedelta
                try:
                    # Parse UTC datetime
                    utc_dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    # Convert to MSK (UTC+3)
                    msk_dt = utc_dt.astimezone(timezone(timedelta(hours=3)))
                    date_formatted = msk_dt.strftime("%Y-%m-%d %H:%M MSK")
                except:
                    date_formatted = date_str[:16].replace('T', ' ') + " MSK"
            else:
                date_formatted = "Unknown MSK"
            
            # Create Telegram link
            link = f"https://t.me/c/{chat_id}/{msg_id}" if msg_id else ""
            link_text = f" [–°—Å—ã–ª–∫–∞]({link})" if link else ""
            
            message_entry = f"{mention_prefix}{i}. **{author}** ({date_formatted}):\n{text}{link_text}\n\n"
            
            # Check if adding this message would exceed Telegram's limit (4096 chars)
            if len(current_part + message_entry) > 4000:  # Leave some margin
                message_parts.append(current_part.strip())
                current_part = f"–°–≤–æ–¥–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel_text} {period_text} (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)\n\n" + message_entry
            else:
                current_part += message_entry
        
        # Add the last part
        if current_part.strip():
            message_parts.append(current_part.strip())
        
        # Send all parts
        target_chat_id = 2514401938 if target_channel == "infotest" else target_channel
        success_count = 0
        
        for part_num, part_text in enumerate(message_parts, 1):
            if len(message_parts) > 1:
                part_header = f"–ß–∞—Å—Ç—å {part_num}/{len(message_parts)}\n\n"
                part_text = part_header + part_text
            
            success = await mcp_session.send_message_to_channel(target_chat_id, part_text)
            if success:
                success_count += 1
                print(f"[DEBUG] Successfully sent part {part_num}/{len(message_parts)}")
            else:
                print(f"[DEBUG] Failed to send part {part_num}/{len(message_parts)}")
        
        if success_count == len(message_parts):
            print(f"[DEBUG] Successfully sent all {len(message_parts)} parts with {len(processed_messages)} messages to {target_channel}")
            return {"error": ""}
        else:
            return {"error": f"Failed to send {len(message_parts) - success_count} out of {len(message_parts)} parts"}
            
    except Exception as e:
        print(f"[DEBUG] Error in send_results_node: {e}")
        return {"error": f"Failed to send results: {str(e)}"}


def create_processing_workflow():
    """Create the LangGraph workflow for message processing."""
    
    workflow = StateGraph(ProcessingState)
    
    # Add nodes
    workflow.add_node("fetch_messages", fetch_messages_from_channels_node)
    workflow.add_node("analyze_messages", analyze_messages_node)
    workflow.add_node("send_results", send_results_node)
    
    # Define the flow
    workflow.set_entry_point("fetch_messages")
    workflow.add_edge("fetch_messages", "analyze_messages")
    workflow.add_edge("analyze_messages", "send_results")
    workflow.add_edge("send_results", END)
    
    return workflow.compile()


async def run_processing_workflow(
    source_channels: List[str] = None,
    time_period_minutes: int = None,  # None = from 8 AM MSK today
    target_channel: str = "infotest",
    custom_filter_rules: List[str] = None
) -> str:
    """Run the complete message processing workflow."""
    
    if source_channels is None:
        source_channels = ["BitKogan / Development"]
    
    # Calculate default period (from 8 AM MSK today)
    if time_period_minutes is None:
        from datetime import datetime, timezone, timedelta
        now_msk = datetime.now(timezone(timedelta(hours=3)))
        today_8am = now_msk.replace(hour=8, minute=0, second=0, microsecond=0)
        if now_msk < today_8am:
            today_8am -= timedelta(days=1)
        time_period_minutes = int((now_msk - today_8am).total_seconds() / 60)
    
    workflow = create_processing_workflow()
    
    initial_state: ProcessingState = {
        "source_channels": source_channels,
        "time_period_minutes": time_period_minutes,
        "target_channel": target_channel,
        "raw_messages": [],
        "processed_messages": [],
        "error": "",
        "mcp_session": None,
        "custom_filter_rules": custom_filter_rules or []
    }
    
    result = await workflow.ainvoke(initial_state)
    
    if result.get("error"):
        return f"Error: {result['error']}"
    
    processed_count = len(result.get("processed_messages", []))
    return f"Successfully processed and sent {processed_count} messages"
